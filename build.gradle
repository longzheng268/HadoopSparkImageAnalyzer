plugins {
    id 'java'
    id 'eclipse'
    id 'application'
}

group = 'com.analyzer'
version = '1.0.0'

// 版本管理
ext {
    // 使用与环境兼容的版本: Spark 3.1.2, Hadoop 3.2.0
    sparkVersion = '3.1.2'
    hadoopVersion = '3.2.0'
    scala_version = '2.12'
}

java {
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

repositories {
    mavenCentral()
}

dependencies {
    // Swing GUI框架（Java内置，无需额外依赖）
    
    // Hadoop/Spark依赖 - 已启用分布式计算
    implementation "org.apache.spark:spark-core_${scala_version}:${sparkVersion}"
    implementation "org.apache.hadoop:hadoop-client:${hadoopVersion}"
    implementation "org.apache.hadoop:hadoop-common:${hadoopVersion}"
    implementation "org.apache.hadoop:hadoop-mapreduce-client-core:${hadoopVersion}"
    implementation "org.apache.hadoop:hadoop-mapreduce-client-common:${hadoopVersion}"
    
    // 日志依赖
    implementation 'org.slf4j:slf4j-api:1.7.30'
    implementation 'org.slf4j:slf4j-simple:1.7.30'
}

application {
    mainClass = 'com.analyzer.Main'
}

// Eclipse配置
eclipse {
    classpath {
        downloadSources = true
        downloadJavadoc = false
    }
}

// 配置编码为UTF-8
tasks.withType(JavaCompile) {
    options.encoding = 'UTF-8'
}
